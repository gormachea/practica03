---
title: "Practica3"
author: "Marco,Guillermo,Celeste"
date: "2026-01-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r carga_libraries, echo = FALSE, message=FALSE, warning=FALSE}
library(readr)
library(dplyr)
library(tidyverse)
library(knitr)
#se omiten mensajes de carga en el documento mediante message=FALSE
```
1. Obtencion y carga de datos
```{r carga_datos, echo = FALSE,warning=FALSE }
epa_http <- read_table("./epa-http.csv",col_names = FALSE, show_col_types = F)
colnames(epa_http) <- c("origen", "fecha", "tipo", "URL", "protocolo", "responsecode", "bytes")
#se omiten warnings de columnas esperadas en ciertos datos, ya que no son relevantes. 
```

```{r limpieza_comillas, echo = TRUE,warning=FALSE }
epa_http$tipo <- gsub('"', '', epa_http$tipo)
epa_http$protocolo <- gsub('"', '', epa_http$protocolo)
#En la importación de datos notamos que los datos de 2 columnas (tipo, procotolo) tomaron las comillas dobles como texto por lo que debemos quitarlas para tener limpios los datos.
```

```{r limpieza_no_200, echo = TRUE,warning=FALSE }
epa_http$bytes <- gsub('-', 0, epa_http$bytes)
epa_http$bytes[epa_http$bytes == ""] <- 0
epa_http[is.na(epa_http)] <- '0'
#En la importación de datos notamos que en la cantidad de bytes transferidos, algunas peticiones tuvieron una respuesta distinta a 200 por lo que no hubo transferencia de datos a lo que se marcó como - o vacío, para poder trabajarlo como numérico debemos limpiar dichos datos no numéricos para que todo coincida.
```

```{r formateo_fecha, echo = TRUE,warning=FALSE }
epa_http <- epa_http %>%
  mutate(fecha = gsub("\\[", "", fecha))
epa_http <- epa_http %>%
  mutate(fecha = gsub("\\]", "", fecha))
epa_http <- epa_http %>%
  separate(
    col = fecha,
    into = c("dias", "horas", "minutos", "segundos"),
    sep = ":",
    convert = TRUE
  )
#Por defecto el TimeStamp viene con el formato [DD:HH:MM:SS] por lo que lo separamos para poder trabajar correctamente.
```

```{r aplicar_formato, echo = TRUE,warning=FALSE }
epa_http$bytes <- as.numeric(epa_http$bytes)

```

```{r Analisis de datos, echo=FALSE}
  # Punto 5: Analizar los distintos tipos de peticiones. 
frecuencia_tipos <- epa_http %>%
  filter(tipo %in% c("GET", "POST", "PUT", "DELETE")) %>%
  count(tipo, sort = TRUE)

frecuencia_tipos


## ---- grafica_metodos_por_rangos, echo=TRUE, warning=FALSE, message=FALSE ----

# 1. Extraer día, hora, minuto y segundo del timestamp
# Formato: [30:00:19:45]
epa_http <- epa_http %>%
  mutate(
    timestamp = str_replace_all(fecha, "\\[|\\]", ""),  # quitar corchetes
    dia   = str_extract(timestamp, "^[0-9]+"),
    hora  = str_extract(timestamp, "(?<=:)[0-9]+(?=:)"),
    segundo = str_extract(timestamp, "[0-9]+$"),

    dia = as.integer(dia),
    hora = as.integer(hora)
  )

# 2. Crear rangos horarios (ejemplo: 0–5, 6–11, 12–17, 18–23)
epa_http <- epa_http %>%
  mutate(
    rango_hora = case_when(
      hora >= 0  & hora < 6  ~ "00-05",
      hora >= 6  & hora < 12 ~ "06-11",
      hora >= 12 & hora < 18 ~ "12-17",
      hora >= 18 & hora <= 23 ~ "18-23",
      TRUE ~ "otro"
    )
  )

# 3. Filtrar métodos HTTP relevantes
metodos_http <- c("GET", "POST", "PUT", "DELETE")

epa_http <- epa_http %>%
  mutate(tipo = str_replace_all(tipo, '"', '')) %>%
  filter(tipo %in% metodos_http)

# 4. Agrupar por día, rango horario y método
resumen <- epa_http %>%
  count(dia, rango_hora, tipo)

# 5. Gráfica
ggplot(resumen, aes(x = rango_hora, y = n, fill = tipo)) +
  geom_col(position = "dodge") +
  facet_wrap(~ dia, ncol = 1) +
  labs(
    title = "Cantidad de métodos HTTP por rangos horarios y por día",
    x = "Rango horario",
    y = "Cantidad de peticiones",
    fill = "Método HTTP"
  ) +
  theme_minimal()



```





