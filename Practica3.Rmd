---
title: "Practica3"
author: "Marco,Guillermo,Celeste"
date: "2026-01-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r carga_libraries, echo = FALSE, message=FALSE, warning=FALSE}
library(readr)
library(dplyr)
library(tidyverse)
library(knitr)
library(ggplot2)
library(mltools)
library(data.table)
library(ggplot2)
#se omiten mensajes de carga en el documento mediante message=FALSE
```
## 1. Obtencion y carga de datos
```{r carga_datos, warning=FALSE }
epa_http <- read_table("./epa-http.csv",col_names = FALSE, show_col_types = F)
colnames(epa_http) <- c("origen", "fecha", "tipo", "URL", "protocolo", "responsecode", "bytes")
#se omiten warnings de columnas esperadas en ciertos datos, ya que no son relevantes. 
```

## 2. Descripcion de los datos analizados

```{r Descripcion_datos, echo = FALSE,warning=FALSE }
descripcion_datos <- data.frame(
  Campo = c("origen", "dias", "horas", "minutos", "segundos", 
            "tipo", "URL", "protocolo", "responsecode", "bytes"),
  Descripcion = c(
    "IP o identificador del cliente",
    "Día del mes extraído del timestamp",
    "Hora del día (0–23)",
    "Minutos (0–59)",
    "Segundos (0–59)",
    "Método HTTP utilizado (GET, POST, PUT, DELETE)",
    "Recurso solicitado por el cliente",
    "Versión del protocolo HTTP",
    "Código de respuesta del servidor",
    "Bytes transferidos en la respuesta"
  )
)

kable(descripcion_datos, caption = "Descripción de los campos del dataset")
```


## 3. Limpieza de datos
```{r limpieza_comillas, echo = TRUE,warning=FALSE }
epa_http$tipo <- gsub('"', '', epa_http$tipo)
epa_http$protocolo <- gsub('"', '', epa_http$protocolo)
#En la importación de datos notamos que los datos de 2 columnas (tipo, procotolo) tomaron las comillas dobles como texto por lo que debemos quitarlas para tener limpios los datos.
```

```{r limpieza_no_200, echo = TRUE,warning=FALSE }
epa_http$bytes <- gsub('-', 0, epa_http$bytes)
epa_http$bytes[epa_http$bytes == ""] <- 0
epa_http[is.na(epa_http)] <- '0'
#En la importación de datos notamos que en la cantidad de bytes transferidos, algunas peticiones tuvieron una respuesta distinta a 200 por lo que no hubo transferencia de datos a lo que se marcó como - o vacío, para poder trabajarlo como numérico debemos limpiar dichos datos no numéricos para que todo coincida.
```

```{r formateo_fecha, echo = TRUE,warning=FALSE }
epa_http <- epa_http %>%
  mutate(fecha = gsub("\\[", "", fecha))
epa_http <- epa_http %>%
  mutate(fecha = gsub("\\]", "", fecha))
epa_http <- epa_http %>%
  separate(
    col = fecha,
    into = c("dias", "horas", "minutos", "segundos"),
    sep = ":",
    convert = TRUE
  )
#Por defecto el TimeStamp viene con el formato [DD:HH:MM:SS] por lo que lo separamos para poder trabajar correctamente.
```

```{r aplicar_formato, echo = TRUE,warning=FALSE }
epa_http$bytes <- as.numeric(epa_http$bytes)

```

## 4. Exploracion de datos
```{r exploracion_datos, echo = FALSE ,warning=FALSE }
epa_http <- epa_http %>%
  mutate(
    responsecode = as.numeric(responsecode),
    tipo_error = case_when(
      responsecode >= 400 & responsecode < 500 ~ "Error 4xx",
      responsecode >= 500 & responsecode < 600 ~ "Error 5xx",
      TRUE ~ "Sin error"
    )
  )


usuarios_error <- epa_http %>%
  filter(tipo_error != "Sin error") %>%
  distinct(origen)

usuarios_sin_error <- epa_http %>%
  filter(tipo_error == "Sin error") %>%
  distinct(origen)

conteo_usuarios <- tibble(
  Categoria = c("Usuarios con errores", "Usuarios sin errores"),
  Usuarios_unicos = c(nrow(usuarios_error), nrow(usuarios_sin_error))
)

kable(conteo_usuarios, caption = "Usuarios únicos con y sin errores")

usuarios_por_error <- epa_http %>%
  filter(tipo_error != "Sin error") %>%
  group_by(tipo_error) %>%
  summarise(usuarios_unicos = n_distinct(origen)) %>%
  arrange(desc(usuarios_unicos))

kable(usuarios_por_error, caption = "Usuarios únicos por tipo de error (4xx y 5xx)")
tipos_error <- epa_http %>%
  filter(tipo_error != "Sin error") %>%
  count(responsecode, sort = TRUE)

kable(tipos_error, caption = "Tipos de errores HTTP presentes en la muestra")


```
## 5. Analisis de datos
```{r Analisis de datos, echo=FALSE}
frecuencia_tipos <- epa_http %>%
  filter(tipo %in% c("GET", "POST", "PUT", "DELETE")) %>%
  count(tipo, sort = TRUE)

kable(
  frecuencia_tipos,
  caption = "Frecuencia de métodos HTTP (GET, POST, PUT, DELETE)"
)
extensiones_imagen <- c(".jpg", ".jpeg", ".png", ".gif", ".bmp")

frecuencia_imagenes <- epa_http %>%
  filter(tipo %in% c("GET", "POST", "PUT", "DELETE")) %>%
  filter(str_detect(tolower(URL), paste(extensiones_imagen, collapse = "|"))) %>%
  count(tipo, sort = TRUE)

kable(
  frecuencia_imagenes,
  caption = "Frecuencia de métodos HTTP de recursos de tipo imagen"
)


```

## 6. Visualizacion de resultados

```{r Visualizar_resultados, echo=FALSE}
epa_http <- epa_http %>%
  mutate(
    rango_hora = cut(
      horas,
      breaks = c(0, 6, 12, 18, 24),
      labels = c("00-06", "06-12", "12-18", "18-24"),
      include.lowest = TRUE,
      right = FALSE
    )
  )
conteo_metodos <- epa_http %>%
  filter(tipo %in% c("GET", "POST", "PUT", "DELETE")) %>% 
  group_by(dias, rango_hora, tipo) %>%
  summarise(conteo = n(), .groups = "drop")

#Grafico 1: Cantidad de metodos HTTP de acuerdo al rango de horarios por ambos dias

ggplot(conteo_metodos, aes(x = rango_hora, y = conteo, fill = tipo)) +
  geom_col(position = "stack") +
  labs(
    title = "Cantidad de métodos HTTP por rangos horarios",
    x = "Rango horario",
    y = "Cantidad de solicitudes",
    fill = "Método HTTP"
  ) +
  theme_minimal(base_size = 14)

#Grafico 2: Trafico por hora que nos sirve para identificar las horas pico. 

lineas_horas <- epa_http %>%
  count(dias, horas)

ggplot(lineas_horas, aes(x = horas, y = n, color = factor(dias))) +
  geom_line(linewidth = 1.2) +
  geom_point() +
  labs(
    title = "Tráfico por hora",
    x = "Hora del día",
    y = "Cantidad de solicitudes",
    color = "Día"
  ) +
  theme_minimal(base_size = 14)

```

## 7. Grafico para visualizar el numero de peticiones servidas a lo largo del tiempo
```{r Peticiones_tiempo, echo = FALSE ,warning=FALSE }
epa_http <- epa_http %>%
  mutate(
    datetime = as.POSIXct(
      sprintf("1995-01-%02d %02d:%02d:%02d", dias, horas, minutos, segundos),
      format = "%Y-%m-%d %H:%M:%S",
      tz = "UTC"
    )
  )

peticiones_tiempo <- epa_http %>%
  count(datetime)

ggplot(peticiones_tiempo, aes(x = datetime, y = n)) +
  geom_line(color = "steelblue", linewidth = 1) +
  labs(
    title = "Número de peticiones servidas a lo largo del tiempo",
    x = "Tiempo",
    y = "Cantidad de peticiones"
  ) +
  theme_minimal(base_size = 14)

```

## 8. Definimos los clústeres y encontramos a cual de ellos pertenece cada peticion o es más cercano.
```{r encontrar_clusteres, echo = FALSE ,warning=FALSE }
num_clusters <- 2
epa_http_numeric <- epa_http[, -c(1, 6, 7, 8, 11, 13)]
epa_http_one_hot <- one_hot(as.data.table(epa_http_numeric), sparsifyNAs = TRUE)
results <- kmeans(epa_http_one_hot, centers = num_clusters, nstart = 25)

num_clusters <- 3
epa_http_one_hot <- one_hot(as.data.table(epa_http_numeric), sparsifyNAs = TRUE)
results <- kmeans(epa_http_one_hot, centers = num_clusters, nstart = 25)


```

## 9. Creamos un gráfico que represente las peticiones que tenemos de acuerdo al clúster definido previamente.
```{r creacion_graficos, echo = FALSE ,warning=FALSE }
epa_http$cluster <- as.factor(results$cluster)

ggplot2::ggplot(epa_http,aes(x = datetime, bytes, colour = cluster))+
  geom_point(alpha = 0.2) + 
  ggtitle(paste("EPA Sever logs K-means analysis with", num_clusters,"clusters"))
```




